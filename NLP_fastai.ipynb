{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHT0wj71u2prmT2bZHA3DG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IphixLi/Fastai-deep-learning/blob/main/NLP_fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqiCOF7zSXqZ",
        "outputId": "d3e0184d-7bb9-4427-8e34-9dc4a22bbec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "from fastbook import *\n",
        "from IPython.display import display,HTML"
      ],
      "metadata": {
        "id": "SXgeHOrRSdhR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP Deep dive\n",
        "\n",
        "we can use language models for many NLP tasks such as autocomplete, grammar checks however to do all that effectively we need to fine-tune the given model to target domain. for example it make sense taining on Wikipedia corpus for doman that uses wikipedia data to understand its vocabulary and semantics.\n",
        "\n",
        "- Universal Language Model Fine-tuning (ULMFit) approach : involves training a language model on a large body of the text first.\n",
        "\n",
        "\n",
        "Each of the steps necessary to create a language model has jargon associated with it from the world of natural language processing, and fastai and PyTorch classes available to help. The steps are:\n",
        "\n",
        "- Tokenization:: Convert the text into a list of words (or characters, or substrings, depending on the granularity of your model)\n",
        "    \n",
        "    - Word-based: split sentence on spaces and other langauge-specific rules . punctualtion marks in individual tokens\n",
        "    - Subword-based: spli words in smaller parts.\n",
        "    - Character-basea\n",
        "\n",
        "- Numericalization:: Make a list of all of the unique words that appear (the vocab), and convert each word into a number, by looking up its index in the vocab\n",
        "- Language model data loader creation:: fastai provides an LMDataLoader class which automatically handles creating a dependent variable that is offset from the independent variable by one token. It also handles some important details, such as how to shuffle the training data in such a way that the dependent and independent variables maintain their structure as required\n",
        "- Language model creation:: We need a special kind of model that does something we haven't seen before: handles input lists which could be arbitrarily big or small.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0X7Af9AqS10h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "### using IMDB data\n",
        "\n",
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.IMDB)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "GmW5_ykXWm9E",
        "outputId": "4aca857e-97a0-48c0-9ab5-87ee84106588"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [144441344/144440600 00:10&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "files = get_text_files(path, folders = ['train', 'test', 'unsup'])"
      ],
      "metadata": {
        "id": "5JDZKbZyWyu1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# part that will be tokenized\n",
        "\n",
        "txt = files[0].open().read();\n",
        "txt[:75]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w8UAKyJYW264",
        "outputId": "90215790-d71b-4a8c-a679-5872fe6ed116"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am Anthony Park, Glenn Park is my father. First off I want to say that th'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fastai uses SpaCy tokenizer for English."
      ],
      "metadata": {
        "id": "KA0EBPmoXYRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy = WordTokenizer()\n",
        "toks = first(spacy([txt]))\n",
        "print(coll_repr(toks, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-znTf2yXivw",
        "outputId": "e73a786e-1b4f-4756-beb1-cdd13f694c76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#361) ['I','am','Anthony','Park',',','Glenn','Park','is','my','father','.','First','off','I','want','to','say','that','the','story','behind','this','movie','and','the','creation','of','the','Amber','Alert'...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first(spacy(['The U.S. dollar 1.00.']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jZfFsiKYAFL",
        "outputId": "c1b82cc5-a76c-4811-d354-768d38a5603e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#5) ['The','U.S.','dollar','1.00','.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now fastai ad additional functionality.\n",
        "Here are some of the main special tokens you'll see:\n",
        "\n",
        "    - xxbos:: Indicates the beginning of a text (here, a review)\n",
        "    - xxmaj:: Indicates the next word begins with a capital (since we lowercased everything)\n",
        "    - xxunk:: Indicates the word is unknown\n",
        "\n",
        "they help us to encode additional information for further NLP tasks.\n",
        "### Example of rules.\n"
      ],
      "metadata": {
        "id": "VdhmqFelYQfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tkn = Tokenizer(spacy)\n",
        "print(coll_repr(tkn(txt), 31))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJiGwBb0aoW7",
        "outputId": "66f51c2b-4a93-4e74-b4f7-0f553e3bf7fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#393) ['xxbos','i','am','xxmaj','anthony','xxmaj','park',',','xxmaj','glenn','xxmaj','park','is','my','father','.','xxmaj','first','off','i','want','to','say','that','the','story','behind','this','movie','and','the'...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "defaults.text_proc_rules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn8dXPB0Y2tq",
        "outputId": "61dd0d18-ab2e-4f30-df36-312ddc67e5f7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function fastai.text.core.fix_html(x)>,\n",
              " <function fastai.text.core.replace_rep(t)>,\n",
              " <function fastai.text.core.replace_wrep(t)>,\n",
              " <function fastai.text.core.spec_add_spaces(t)>,\n",
              " <function fastai.text.core.rm_useless_spaces(t)>,\n",
              " <function fastai.text.core.replace_all_caps(t)>,\n",
              " <function fastai.text.core.replace_maj(t)>,\n",
              " <function fastai.text.core.lowercase(t, add_bos=True, add_eos=False)>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    - fix_html:: Replaces special HTML characters with a readable version (IMDb reviews have quite a few of these)\n",
        "    - replace_rep:: Replaces any character repeated three times or more with a special token for repetition (xxrep), the number of times it's repeated, then the character\n",
        "    - replace_wrep:: Replaces any word repeated three times or more with a special token for word repetition (xxwrep), the number of times it's repeated, then the word\n",
        "    - spec_add_spaces:: Adds spaces around / and #\n",
        "    - rm_useless_spaces:: Removes all repetitions of the space character\n",
        "    - replace_all_caps:: Lowercases a word written in all caps and adds a special token for all caps (xxup) in front of it\n",
        "    - replace_maj:: Lowercases a capitalized word and adds a special token for capitalized (xxmaj) in front of it\n",
        "    - lowercase:: Lowercases all text and adds a special token at the beginning (xxbos) and/or the end (xxeos)"
      ],
      "metadata": {
        "id": "E70wL-WnZkOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coll_repr(tkn('©   Fast.ai www.fast.ai/INDEX'), 31)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TRuBSDcoZHcq",
        "outputId": "9bbbc06c-f76c-43da-e30f-c23f0dd3b0d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"(#11) ['xxbos','©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## subword Tokenization\n",
        "\n",
        "Some langauge presentations doesn't really add spaces for separating information.\n",
        "\n",
        "to handle this, it is better to use subword tokenization\n",
        "\n",
        "- Analyze a corpus of documents to find the most commonly occurring groups of letters. These become the vocab.\n",
        "- Tokenize the corpus using this vocab of subword units.\n"
      ],
      "metadata": {
        "id": "7TqjhSb2bIWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txts = L(o.open().read() for o in files[:2000])"
      ],
      "metadata": {
        "id": "JkHb7COGZjRS"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}